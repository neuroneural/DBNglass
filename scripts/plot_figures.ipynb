{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import isnan\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import wandb\n",
    "\n",
    "dataset_match = {\n",
    "    \"fbirn\": \"FBIRN ICA\",\n",
    "    \"fbirn_roi\": \"FBIRN Schaefer 200 ROI\",\n",
    "    \"bsnip\": \"BSNIP ICA\",\n",
    "    \"cobre\": \"COBRE ICA\",\n",
    "\n",
    "    \"abide\": \"ABIDE1 ICA 569 subjects\",\n",
    "    \"abide_869\": \"ABIDE1 ICA\",\n",
    "    \"abide_roi\": \"ABIDE1 Schaefer 200 ROI\",\n",
    "\n",
    "    \"oasis\": \"OASIS3 ICA\",\n",
    "    \"adni\": \"ADNI ICA\",\n",
    "\n",
    "    \"hcp\": \"HCP ICA\",\n",
    "    \"hcp_roi\": \"HCP Schaefer 200 ROI\",\n",
    "    \"hcp_non_mni\": \"HCP Deskian/Killiany ROI Old\",\n",
    "    \"hcp_non_mni_2\": \"HCP Deskian/Killiany ROI\",\n",
    "    \"hcp_mni\": \"HCP Deskian/Killiany ROI MNI Oldest\",\n",
    "    \"hcp_mni_2\": \"HCP Deskian/Killiany ROI MNI Old\",\n",
    "    \"hcp_mni_3\": \"HCP Deskian/Killiany ROI MNI\",\n",
    "\n",
    "    \"ukb\": \"UK Biobank (Sex) ICA\",\n",
    "    \"ukb_age_bins\": \"UK Biobank (Age-Sex) ICA\",\n",
    "\n",
    "    \"time_fbirn\": \"FBIRN (Time Direction) ICA\",\n",
    "\n",
    "    \"fbirn_bsnip\": \"FxB\",\n",
    "    \"fbirn_cobre\": \"FxC\",\n",
    "\n",
    "    \"bsnip_fbirn\": \"BxF\",\n",
    "    \"bsnip_cobre\": \"BxC\",\n",
    "\n",
    "    \"cobre_fbirn\": \"CxF\",\n",
    "    \"cobre_bsnip\": \"CxB\",\n",
    "\n",
    "    \"oasis_adni\": \"OxA\",\n",
    "    \"adni_oasis\": \"AxO\",\n",
    "}\n",
    "\n",
    "model_match = {\n",
    "    \"mlp\": \"MLP\",\n",
    "    \"lstm\": \"LSTM\",\n",
    "    \"mean_lstm\": r\"$\\mu$LSTM\",\n",
    "    \"transformer\": \"Transformer\",\n",
    "    \"mean_transformer\": r\"$\\mu$Transformer\",\n",
    "    \"milc\": \"MILC\",\n",
    "    \"stdim\": \"ST-DIM\",\n",
    "    \"dice\": \"DICE\",\n",
    "    \"bnt\": \"BNT\",\n",
    "    \"fbnetgen\": \"FBNetGen\",\n",
    "    \"brainnetcnn\": \"BrainNetCNN\",\n",
    "    \"lr\": \"LR\",\n",
    "}\n",
    "\n",
    "def fix_run(run, dataset):\n",
    "    for _, row in run.history().iterrows():\n",
    "        if f\"{dataset}score\" in row and f\"{dataset}accuracy\" in row and \"training_time\" in row and f\"{dataset}average_time\" in row:\n",
    "            if row[f\"{dataset}score\"] is not None and row[f\"{dataset}accuracy\"] is not None and row[\"training_time\"] is not None and row[f\"{dataset}average_time\"] is not None:\n",
    "                if not isnan(row[f\"{dataset}score\"]) and not isnan(row[f\"{dataset}accuracy\"]) and not isnan(row[\"training_time\"]) and not isnan(row[f\"{dataset}average_time\"]):\n",
    "                    auc = row[f\"{dataset}score\"]\n",
    "                    acc = row[f\"{dataset}accuracy\"]\n",
    "                    train_t = row[\"training_time\"]\n",
    "                    inf_t= row[f\"{dataset}average_time\"]\n",
    "                    break\n",
    "    \n",
    "    run.summary[f\"{dataset}score\"] = auc\n",
    "    run.summary[f\"{dataset}accuracy\"] = acc\n",
    "    run.summary[\"training_time\"] = train_t\n",
    "    run.summary[f\"{dataset}average_time\"] = inf_t\n",
    "\n",
    "    run.summary.update()\n",
    "\n",
    "    return auc, acc, train_t, inf_t\n",
    "\n",
    "def load_run(proj_name, dataset):\n",
    "    if dataset is not None:\n",
    "        dataset += \"_\"\n",
    "    else:\n",
    "        dataset = \"test_\"\n",
    "\n",
    "    api = wandb.Api(timeout=19)\n",
    "    # Project is specified by <entity/project-name>\n",
    "    runs = api.runs(f\"pavalipopov/{proj_name}\")\n",
    "\n",
    "    summary_list = []\n",
    "    runs_list = []\n",
    "    config_list = []\n",
    "    for i, run in enumerate(runs): \n",
    "        # print(f\"Run {i}\")\n",
    "        # .summary contains the output keys/values for metrics like accuracy.\n",
    "        #  We call ._json_dict to omit large files \n",
    "        summary_list.append(run.summary._json_dict)\n",
    "        config_list.append(run.config)\n",
    "        runs_list.append(run)\n",
    "\n",
    "\n",
    "    AUC_score = []\n",
    "    accuracy = []\n",
    "    train_time = []\n",
    "    inference_time = []\n",
    "    params = []\n",
    "    shuffling = []\n",
    "\n",
    "    for i, summary in enumerate(summary_list):\n",
    "        everything_is_cool = True\n",
    "        everything_is_cool = everything_is_cool and f\"{dataset}score\" in summary and summary[f\"{dataset}score\"] is not None\n",
    "        everything_is_cool = everything_is_cool and f\"{dataset}accuracy\" in summary and summary[f\"{dataset}accuracy\"] is not None\n",
    "        everything_is_cool = everything_is_cool and \"training_time\" in summary and summary[\"training_time\"] is not None\n",
    "        everything_is_cool = everything_is_cool and f\"{dataset}average_time\" in summary and summary[f\"{dataset}average_time\"] is not None\n",
    "\n",
    "        if everything_is_cool:\n",
    "            AUC_score.append(summary[f\"{dataset}score\"])\n",
    "            accuracy.append(summary[f\"{dataset}accuracy\"])\n",
    "            train_time.append(summary[\"training_time\"])\n",
    "            inference_time.append(summary[f\"{dataset}average_time\"])\n",
    "        else:\n",
    "            print(f\"Run {i} summary is broken, fixing it\")\n",
    "            auc, acc, train_t, inf_t = fix_run(runs_list[i], dataset)\n",
    "            AUC_score.append(auc)\n",
    "            accuracy.append(acc)\n",
    "            train_time.append(train_t)\n",
    "            inference_time.append(inf_t)\n",
    "\n",
    "        if \"params\" in summary:\n",
    "            params.append(summary[\"params\"])\n",
    "        else:\n",
    "            params.append(None)\n",
    "\n",
    "        if \"permute\" in config_list[i][\"general\"]:\n",
    "            if config_list[i][\"general\"][\"permute\"] == False:\n",
    "                shuffling.append(\"None\")\n",
    "            else:\n",
    "                shuffling.append(config_list[i][\"general\"][\"permute\"])\n",
    "        else:\n",
    "            shuffling.append(\"None\")\n",
    "    \n",
    "    return AUC_score, accuracy, train_time, inference_time, params, shuffling\n",
    "\n",
    "def load_metrics(paths_dict, ds_dict, model_dict):\n",
    "    data_list = []\n",
    "\n",
    "    for model_name in paths_dict:\n",
    "        print(model_name)\n",
    "        for dataset_name in paths_dict[model_name]:\n",
    "            print(\"\\t \", dataset_name)\n",
    "            \n",
    "            if len(paths_dict[model_name][dataset_name]) == 2:\n",
    "                path = paths_dict[model_name][dataset_name][0]\n",
    "                dataset = paths_dict[model_name][dataset_name][1]\n",
    "            elif len(paths_dict[model_name][dataset_name]) == 1:\n",
    "                path = paths_dict[model_name][dataset_name][0]\n",
    "                dataset = \"test\"\n",
    "            else:\n",
    "                raise NotImplementedError()\n",
    "\n",
    "            print(\"\\t\\t sub_dataset:\", dataset)\n",
    "\n",
    "            AUC_score, accuracy, train_time, inference_time, params, shuffling = load_run(path, dataset)\n",
    "            \n",
    "            if dataset != \"test\":\n",
    "                dataset = dataset_name + \"_\" + dataset\n",
    "            else:\n",
    "                dataset = dataset_name\n",
    "            length = len(AUC_score)\n",
    "\n",
    "            data_list.append(\n",
    "                pd.DataFrame(\n",
    "                    {\n",
    "                        \"Model\": [model_dict[model_name]]*length,\n",
    "                        \"Dataset\": [ds_dict[dataset]]*length,\n",
    "                        \"AUROC\": AUC_score,\n",
    "                        \"Accuracy\": accuracy,\n",
    "                        \"Train time\": train_time,\n",
    "                        \"Inference time\": inference_time,\n",
    "                        \"Trainable params\": params,\n",
    "                        \"Shuffling\": shuffling,\n",
    "                    }\n",
    "                )\n",
    "            )\n",
    "    \n",
    "    return pd.concat(data_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "projects = {\n",
    "    \"mlp\": {\n",
    "        \"hcp\": (\"all_mni-exp-mlp_defHP-hcp\", ),\n",
    "        \"hcp_roi\": (\"all_mni-exp-mlp_defHP-hcp_roi\", ),\n",
    "        \"hcp_non_mni_2\": (\"all_mni-exp-mlp_defHP-hcp_non_mni_2\", ),\n",
    "        \"hcp_mni_3\": (\"all_mni-exp-mlp_defHP-hcp_mni_3\", ),\n",
    "    },\n",
    "    \"lstm\": {\n",
    "        \"hcp\": (\"all_mni-exp-lstm_defHP-hcp\", ),\n",
    "        \"hcp_roi\": (\"all_mni-exp-lstm_defHP-hcp_roi\", ),\n",
    "        \"hcp_non_mni_2\": (\"all_mni-exp-lstm_defHP-hcp_non_mni_2\", ),\n",
    "        \"hcp_mni_3\": (\"all_mni-exp-lstm_defHP-hcp_mni_3\", ),\n",
    "    },\n",
    "    \"mean_lstm\": {\n",
    "        \"hcp\": (\"all_mni-exp-mean_lstm_defHP-hcp\", ),\n",
    "        \"hcp_roi\": (\"all_mni-exp-mean_lstm_defHP-hcp_roi\", ),\n",
    "        \"hcp_non_mni_2\": (\"all_mni-exp-mean_lstm_defHP-hcp_non_mni_2\", ),\n",
    "        \"hcp_mni_3\": (\"all_mni-exp-mean_lstm_defHP-hcp_mni_3\", ),\n",
    "    },\n",
    "    \"transformer\": {\n",
    "        \"hcp\": (\"all_mni-exp-transformer_defHP-hcp\", ),\n",
    "        \"hcp_roi\": (\"all_mni-exp-transformer_defHP-hcp_roi\", ),\n",
    "        \"hcp_non_mni_2\": (\"all_mni-exp-transformer_defHP-hcp_non_mni_2\", ),\n",
    "        \"hcp_mni_3\": (\"all_mni-exp-transformer_defHP-hcp_mni_3\", ),\n",
    "    },\n",
    "    \"mean_transformer\": {\n",
    "        \"hcp\": (\"all_mni-exp-mean_transformer_defHP-hcp\", ),\n",
    "        \"hcp_roi\": (\"all_mni-exp-mean_transformer_defHP-hcp_roi\", ),\n",
    "        \"hcp_non_mni_2\": (\"all_mni-exp-mean_transformer_defHP-hcp_non_mni_2\", ),\n",
    "        \"hcp_mni_3\": (\"all_mni-exp-mean_transformer_defHP-hcp_mni_3\", ),\n",
    "    },\n",
    "}\n",
    "\n",
    "projects_single = {\n",
    "    \"mlp\": {\n",
    "        \"hcp\": (\"all_mni-exp-mlp_defHP-hcp-perm_Single\", ),\n",
    "        \"hcp_roi\": (\"all_mni-exp-mlp_defHP-hcp_roi-perm_Single\", ),\n",
    "        \"hcp_non_mni_2\": (\"all_mni-exp-mlp_defHP-hcp_non_mni_2-perm_Single\", ),\n",
    "        \"hcp_mni_3\": (\"all_mni-exp-mlp_defHP-hcp_mni_3-perm_Single\", ),\n",
    "    },\n",
    "    \"lstm\": {\n",
    "        \"hcp\": (\"all_mni-exp-lstm_defHP-hcp-perm_Single\", ),\n",
    "        \"hcp_roi\": (\"all_mni-exp-lstm_defHP-hcp_roi-perm_Single\", ),\n",
    "        \"hcp_non_mni_2\": (\"all_mni-exp-lstm_defHP-hcp_non_mni_2-perm_Single\", ),\n",
    "        \"hcp_mni_3\": (\"all_mni-exp-lstm_defHP-hcp_mni_3-perm_Single\", ),\n",
    "    },\n",
    "    \"mean_lstm\": {\n",
    "        \"hcp\": (\"all_mni-exp-mean_lstm_defHP-hcp-perm_Single\", ),\n",
    "        \"hcp_roi\": (\"all_mni-exp-mean_lstm_defHP-hcp_roi-perm_Single\", ),\n",
    "        \"hcp_non_mni_2\": (\"all_mni-exp-mean_lstm_defHP-hcp_non_mni_2-perm_Single\", ),\n",
    "        \"hcp_mni_3\": (\"all_mni-exp-mean_lstm_defHP-hcp_mni_3-perm_Single\", ),\n",
    "    },\n",
    "    \"transformer\": {\n",
    "        \"hcp\": (\"all_mni-exp-transformer_defHP-hcp-perm_Single\", ),\n",
    "        \"hcp_roi\": (\"all_mni-exp-transformer_defHP-hcp_roi-perm_Single\", ),\n",
    "        \"hcp_non_mni_2\": (\"all_mni-exp-transformer_defHP-hcp_non_mni_2-perm_Single\", ),\n",
    "        \"hcp_mni_3\": (\"all_mni-exp-transformer_defHP-hcp_mni_3-perm_Single\", ),\n",
    "    },\n",
    "    \"mean_transformer\": {\n",
    "        \"hcp\": (\"all_mni-exp-mean_transformer_defHP-hcp-perm_Single\", ),\n",
    "        \"hcp_roi\": (\"all_mni-exp-mean_transformer_defHP-hcp_roi-perm_Single\", ),\n",
    "        \"hcp_non_mni_2\": (\"all_mni-exp-mean_transformer_defHP-hcp_non_mni_2-perm_Single\", ),\n",
    "        \"hcp_mni_3\": (\"all_mni-exp-mean_transformer_defHP-hcp_mni_3-perm_Single\", ),\n",
    "    },\n",
    "}\n",
    "\n",
    "projects_multiple = {\n",
    "    \"mlp\": {\n",
    "        \"hcp\": (\"all_mni-exp-mlp_defHP-hcp-perm_Multiple\", ),\n",
    "        \"hcp_roi\": (\"all_mni-exp-mlp_defHP-hcp_roi-perm_Multiple\", ),\n",
    "        \"hcp_non_mni_2\": (\"all_mni-exp-mlp_defHP-hcp_non_mni_2-perm_Multiple\", ),\n",
    "        \"hcp_mni_3\": (\"all_mni-exp-mlp_defHP-hcp_mni_3-perm_Multiple\", ),\n",
    "    },\n",
    "    \"lstm\": {\n",
    "        \"hcp\": (\"all_mni-exp-lstm_defHP-hcp-perm_Multiple\", ),\n",
    "        \"hcp_roi\": (\"all_mni-exp-lstm_defHP-hcp_roi-perm_Multiple\", ),\n",
    "        \"hcp_non_mni_2\": (\"all_mni-exp-lstm_defHP-hcp_non_mni_2-perm_Multiple\", ),\n",
    "        \"hcp_mni_3\": (\"all_mni-exp-lstm_defHP-hcp_mni_3-perm_Multiple\", ),\n",
    "    },\n",
    "    \"mean_lstm\": {\n",
    "        \"hcp\": (\"all_mni-exp-mean_lstm_defHP-hcp-perm_Multiple\", ),\n",
    "        \"hcp_roi\": (\"all_mni-exp-mean_lstm_defHP-hcp_roi-perm_Multiple\", ),\n",
    "        \"hcp_non_mni_2\": (\"all_mni-exp-mean_lstm_defHP-hcp_non_mni_2-perm_Multiple\", ),\n",
    "        \"hcp_mni_3\": (\"all_mni-exp-mean_lstm_defHP-hcp_mni_3-perm_Multiple\", ),\n",
    "    },\n",
    "    \"transformer\": {\n",
    "        \"hcp\": (\"all_mni-exp-transformer_defHP-hcp-perm_Multiple\", ),\n",
    "        \"hcp_roi\": (\"all_mni-exp-transformer_defHP-hcp_roi-perm_Multiple\", ),\n",
    "        \"hcp_non_mni_2\": (\"all_mni-exp-transformer_defHP-hcp_non_mni_2-perm_Multiple\", ),\n",
    "        \"hcp_mni_3\": (\"all_mni-exp-transformer_defHP-hcp_mni_3-perm_Multiple\", ),\n",
    "    },\n",
    "    \"mean_transformer\": {\n",
    "        \"hcp\": (\"all_mni-exp-mean_transformer_defHP-hcp-perm_Multiple\", ),\n",
    "        \"hcp_roi\": (\"all_mni-exp-mean_transformer_defHP-hcp_roi-perm_Multiple\", ),\n",
    "        \"hcp_non_mni_2\": (\"all_mni-exp-mean_transformer_defHP-hcp_non_mni_2-perm_Multiple\", ),\n",
    "        \"hcp_mni_3\": (\"all_mni-exp-mean_transformer_defHP-hcp_mni_3-perm_Multiple\", ),\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_n = load_metrics(projects, dataset_match, model_match)\n",
    "data_s = load_metrics(projects_single, dataset_match, model_match)\n",
    "data_m = load_metrics(projects_multiple, dataset_match, model_match)\n",
    "\n",
    "data = pd.concat([data_n, data_s, data_m])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## All results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.ticker as ticker\n",
    "from statannot import add_stat_annotation\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sns.reset_orig()\n",
    "sns.set_theme(\n",
    "    style=\"whitegrid\", \n",
    "    font_scale = 1.5,\n",
    "    rc={'figure.figsize':(9,4)},\n",
    ")\n",
    "\n",
    "plot_data = data.query(\n",
    "        \"Shuffling == 'None'\")\n",
    "\n",
    "models = [\n",
    "    \"MLP\", \n",
    "    'LSTM', \n",
    "    r'$\\mu$LSTM', \n",
    "    'Transformer', \n",
    "    r'$\\mu$Transformer', \n",
    "    \"MILC\", \n",
    "    \"ST-DIM\", \n",
    "    \"DICE\", \n",
    "    \"BNT\", \n",
    "    \"FBNetGen\", \n",
    "    \"BrainNetCNN\", \n",
    "    \"LR\"\n",
    "]\n",
    "datasets = [\n",
    "    \"HCP Deskian/Killiany ROI\",\n",
    "    \"HCP Deskian/Killiany ROI MNI\",\n",
    "    \"HCP Schaefer 200 ROI\",\n",
    "    \"HCP ICA\",\n",
    "]\n",
    "hue_order = datasets\n",
    "x_order = [\n",
    "    \"MLP\", \n",
    "    r'$\\mu$LSTM', \n",
    "    r'$\\mu$Transformer', \n",
    "    'LSTM', \n",
    "    'Transformer'\n",
    "]\n",
    "\n",
    "palette = { item: plt.cm.tab20(i) for i, item in enumerate(datasets)}\n",
    "\n",
    "ax = sns.boxplot(\n",
    "    x=\"Model\", \n",
    "    order=x_order,\n",
    "    y=\"AUROC\",\n",
    "    hue=\"Dataset\",\n",
    "    hue_order=hue_order,\n",
    "    data=plot_data,\n",
    "    palette=palette,\n",
    "    showfliers = False\n",
    ")\n",
    "\n",
    "ax.set(xlabel=None)\n",
    "ax.axhline(0.5)\n",
    "\n",
    "plt.yticks([0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0])\n",
    "# plt.legend(bbox_to_anchor=(1.01, 1.0), loc='upper left', borderaxespad=0)\n",
    "plt.legend(bbox_to_anchor=(0.01, -0.15), loc='upper left', borderaxespad=0)\n",
    "# plt.title(label=\"ICA - Neuromark\")\n",
    "\n",
    "plt.ylim(0.45, 1)\n",
    "# ax.set_xlim(xmin=-0.5, xmax=8.5)\n",
    "\n",
    "add_stat_annotation(ax, data=plot_data, x=\"Model\", order=x_order, y=\"AUROC\", hue=\"Dataset\", hue_order=hue_order,\n",
    "                    box_pairs=[\n",
    "                        ((\"MLP\", \"HCP Deskian/Killiany ROI\"), (\"MLP\", \"HCP Deskian/Killiany ROI MNI\")),\n",
    "                        ((\"LSTM\", \"HCP Deskian/Killiany ROI\"), (\"LSTM\", \"HCP Deskian/Killiany ROI MNI\")),\n",
    "                        ((r'$\\mu$LSTM', \"HCP Deskian/Killiany ROI\"), (r'$\\mu$LSTM', \"HCP Deskian/Killiany ROI MNI\")),\n",
    "                        ((\"Transformer\", \"HCP Deskian/Killiany ROI\"), (\"Transformer\", \"HCP Deskian/Killiany ROI MNI\")),\n",
    "                        ((r'$\\mu$Transformer', \"HCP Deskian/Killiany ROI\"), (r'$\\mu$Transformer', \"HCP Deskian/Killiany ROI MNI\")),\n",
    "                    ],\n",
    "                    test='Wilcoxon', text_format='star', loc='inside', verbose=1, text_offset=-4, \n",
    "                    pvalue_thresholds = [[0.05, \"*\"], [1, u'\\N{DEGREE SIGN}']],\n",
    "                    line_offset=0.01, line_offset_to_box=0.01, line_height=0.01, fontsize=24)\n",
    "\n",
    "# plt.show()\n",
    "plt.savefig(\n",
    "    \"comparison.png\",\n",
    "    format=\"png\",\n",
    "    dpi=300,\n",
    "    bbox_inches='tight',\n",
    ")\n",
    "# plt.savefig(\n",
    "#     \"comparison.svg\",\n",
    "#     format=\"svg\",\n",
    "#     # dpi=300,\n",
    "#     bbox_inches='tight',\n",
    "# )\n",
    "plt.close()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shuffling results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.ticker as ticker\n",
    "from statannot import add_stat_annotation\n",
    "\n",
    "sns.reset_orig()\n",
    "sns.set_theme(\n",
    "    style=\"whitegrid\", \n",
    "    font_scale = 1.5,\n",
    ")\n",
    "\n",
    "models = [\n",
    "    \"MLP\", \n",
    "    'LSTM', \n",
    "    r'$\\mu$LSTM', \n",
    "    'Transformer', \n",
    "    r'$\\mu$Transformer', \n",
    "    \"MILC\", \n",
    "    \"ST-DIM\", \n",
    "    \"DICE\", \n",
    "    \"BNT\", \n",
    "    \"FBNetGen\", \n",
    "    \"BrainNetCNN\", \n",
    "    \"LR\"\n",
    "]\n",
    "\n",
    "shuffling = [\"False\", \"True\"]\n",
    "palette = { item: plt.cm.tab20(i) for i, item in enumerate(shuffling)}\n",
    "hue_order = shuffling\n",
    "\n",
    "x_order = [\n",
    "    \"MLP\", \n",
    "    r'$\\mu$LSTM', \n",
    "    r'$\\mu$Transformer', \n",
    "    'LSTM', \n",
    "    'Transformer'\n",
    "]\n",
    "\n",
    "datasets = [\n",
    "    \"HCP Deskian/Killiany ROI\",\n",
    "    \"HCP Deskian/Killiany ROI MNI\",\n",
    "    \"HCP Schaefer 200 ROI\",\n",
    "    \"HCP ICA\",\n",
    "]\n",
    "\n",
    "fig = plt.figure(constrained_layout=True, figsize=(9*len(datasets)//2, 4*len(datasets)//2))\n",
    "axs = fig.subplots(len(datasets)//2, len(datasets)//2)\n",
    "\n",
    "sns.set_theme(\n",
    "    style=\"whitegrid\", \n",
    "    font_scale = 2, \n",
    ")\n",
    "\n",
    "for i, dataset in enumerate(datasets):\n",
    "    plot_data = data.query(\n",
    "        \"Dataset == @dataset\")\n",
    "    plot_data = plot_data.query(\n",
    "        \"Shuffling in ['None', 'Multiple']\")\n",
    "\n",
    "    plot_data = plot_data.replace('None', 'False')\n",
    "    plot_data = plot_data.replace('Multiple', 'True')\n",
    "\n",
    "    sns.boxplot(\n",
    "        x=\"Model\", \n",
    "        order=x_order,\n",
    "        y=\"AUROC\",\n",
    "        hue=\"Shuffling\",\n",
    "        hue_order=hue_order,\n",
    "        data=plot_data,\n",
    "        palette=palette,\n",
    "        showfliers = False,\n",
    "        ax = axs[i//2][i%2]\n",
    "    )\n",
    "    \n",
    "\n",
    "    axs[i//2][i%2].set_yticks([0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0])\n",
    "    # subfigs[i].axhline(0.5)\n",
    "    if i%2 == 1:\n",
    "        axs[i//2][i%2].set(yticklabels=[])\n",
    "        axs[i//2][i%2].set(ylabel=None)\n",
    "\n",
    "    if i%2 == 1 and i//2 == 0:\n",
    "        axs[i//2][i%2].legend(bbox_to_anchor=(1.01, 1.0), loc='upper left', borderaxespad=0, title=\"Shuffling\")\n",
    "    else:\n",
    "        axs[i//2][i%2].legend([],[], frameon=False)\n",
    "        \n",
    "    axs[i//2][i%2].set_title(dataset, fontsize=16)\n",
    "\n",
    "    axs[i//2][i%2].set_ylim(0.45, 1.0)\n",
    "    axs[i//2][i%2].axhline(0.5)\n",
    "    axs[i//2][i%2].set(xlabel=None)\n",
    "\n",
    "    # try:\n",
    "    #     add_stat_annotation(axs[i], data=plot_data, x=\"Model\", y=\"AUC\", hue=\"Permuted\",\n",
    "    #             box_pairs=[\n",
    "    #                 ((\"MLP\", True), (\"MLP\", False)),\n",
    "    #                 ((\"LSTM\", True), (\"LSTM\", False)),\n",
    "    #                 ((\"Mean LSTM\", True), (\"Mean LSTM\", False)),\n",
    "    #                 ((\"TF\", True), (\"TF\", False)),\n",
    "    #                 ((\"Mean TF\", True), (\"Mean TF\", False)),\n",
    "    #             ],\n",
    "    #             test='Wilcoxon', text_format='star', loc='inside', verbose=1, text_offset=-4, \n",
    "    #             pvalue_thresholds = [[0.05, \"*\"], [1, u'\\N{DEGREE SIGN}']],\n",
    "    #             line_offset=0.01, line_offset_to_box=0.02, line_height=0.01, fontsize=13)\n",
    "    # except ValueError:\n",
    "    #     pass\n",
    "\n",
    "# plt.show()\n",
    "plt.savefig(\n",
    "    \"./shuffling.png\",\n",
    "    format=\"png\",\n",
    "    dpi=300,\n",
    "    bbox_inches='tight',\n",
    "    transparent=False,\n",
    ")\n",
    "plt.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlp_nn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
